{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Learning (ZSL) Training and Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:      3.7.8\n",
      "PyTorch Version:     1.7.1+cu101\n",
      "Torchvision Version: 0.8.2+cu101\n",
      "CUDA Version:        10.1\n",
      "\n",
      "***********************************\n",
      "GPU Available:  True\n",
      "Current Device: cuda:0 (Tesla T4)\n",
      "***********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# this is necessary to use the common functions\n",
    "# assumes directory structure was maintained\n",
    "sys.path.insert(0, '../common/')\n",
    "# from common.torch_utils import train_model,get_device\n",
    "# from torch_utils import (train_model, \n",
    "#                          mnist_dataloader, \n",
    "#                          dataset_preview)\n",
    "from torch_utils import *\n",
    "\n",
    "# print some versions\n",
    "print(f'Python Version:      {platform.python_version()}')\n",
    "print(f'PyTorch Version:     {torch.__version__}')\n",
    "print(f'Torchvision Version: {torchvision.__version__}')\n",
    "print(f'CUDA Version:        {torch.version.cuda}')\n",
    "\n",
    "# get device (defaults to GPU if available)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We need to collect the MNIST data and create the dataloaders for PyTorch. To make a clean notebook, we have created a helper function to do most of the work (refer to `/src/common/torch_utils.py`). For training we will use a batch_size of 32 images, similar to the base model. To demonstrate the capabilities of ZSL on limited datasets, we must take a two step approach:\n",
    "1. Training ZSL using the same baseline process (i.e., on the entire MNIST dataset)\n",
    "2. Training ZSL using a small subset of the MNIST dataset (we will try a few sizes)\n",
    "\n",
    "We can then we will have a matrix of comparisons:  \n",
    "\n",
    "||||\n",
    "|-|-|-|\n",
    "||ZSL+|Baseline+|\n",
    "|ZSL-|||\n",
    "|Baseline-|||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into the MNIST dataset, let's experiment using the data from [1].\n",
    "\n",
    "$$\n",
    "@inproceedings{li2019rethinking,\n",
    "  title={Rethinking Zero-Shot Learning: A Conditional Visual Classification Perspective},\n",
    "  author={Li, Kai and Min, Martin Renqiang and Fu, Yun},\n",
    "  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n",
    "  pages={3583--3592},\n",
    "  year={2019}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to unzip, '../../data/zsl-example/data.zip' does not exist!\n"
     ]
    }
   ],
   "source": [
    "# get the example data\n",
    "zsl_data_dir = '../../data/zsl-example'\n",
    "zsl_example_data = 'http://www.robots.ox.ac.uk/~lz/DEM_cvpr2017/data.zip'\n",
    "if not os.path.isdir(zsl_data_dir):\n",
    "    os.mkdir(zsl_data_dir)\n",
    "# download data and clone project\n",
    "# ! wget $zsl_example_data -P $zsl_data_dir \n",
    "# ! git clone https://github.com/kailigo/cvcZSL.git\n",
    "\n",
    "zsl_data_zip = os.path.join(zsl_data_dir,os.path.basename(zsl_example_data))\n",
    "if os.path.isfile(zsl_data_zip):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zsl_data_zip,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(zsl_data_dir)\n",
    "    # cleanup, we don't need the zip now\n",
    "\n",
    "    os.remove(zsl_data_zip)\n",
    "    if not os.path.isfile(zsl_data_zip):\n",
    "        print('Clean-up complete!')\n",
    "else:\n",
    "    print(f'Nothing to unzip, \\'{zsl_data_zip}\\' does not exist!')\n",
    "\n",
    "\n",
    "\n",
    "tmp = os.path.splitext(os.path.basename(zsl_example_data))[0]\n",
    "zsl_data_dir = os.path.join(zsl_data_dir,tmp)\n",
    "if not os.path.isdir(zsl_data_dir):\n",
    "    print('ERROR: ZSL example data dir does not exist, \\'{zsl_data_dir}\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='../../data/zsl-example/data/AwA1_data', gamma=0.5, hidden_dim=1600, log_file='logs/eps_lr5_opt4_ss500_w16_s4', log_to_file=True, lr=1e-05, model_file='models/lr5_opt4_ss500_w16_s4.pt', nthreads=8, num_epochs=10, opt_decay=0.0001, shots=4, step_size=500, ways=16, weight_model='weightnet')\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "cvcZSL/train.py:84: UserWarning: This overload of baddbmm is deprecated:\n",
      "\tbaddbmm(Number beta, Tensor input, Number alpha, Tensor batch1, Tensor batch2, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tbaddbmm(Tensor input, Tensor batch1, Tensor batch2, *, Number beta, Number alpha, Tensor out) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  cls_scores = scale_cls * torch.baddbmm(1.0, bias.view(1, 1, 1), 1.0, features, cls_weights.transpose(1,2))\n",
      "ep: 0,  lr: 0.000010, loss: 1.2317,  zsl: 0.5378, gzsl: seen=0.8436, unseen=0.0373, h=0.0714\n",
      "ep: 1,  lr: 0.000010, loss: 0.8633,  zsl: 0.5535, gzsl: seen=0.8517, unseen=0.0373, h=0.0716\n",
      "ep: 2,  lr: 0.000010, loss: 0.8494,  zsl: 0.5631, gzsl: seen=0.8529, unseen=0.0507, h=0.0957\n",
      "ep: 3,  lr: 0.000010, loss: 0.8463,  zsl: 0.5722, gzsl: seen=0.8524, unseen=0.0520, h=0.0980\n",
      "ep: 4,  lr: 0.000010, loss: 0.8342,  zsl: 0.5739, gzsl: seen=0.8506, unseen=0.0725, h=0.1336\n",
      "ep: 5,  lr: 0.000010, loss: 0.8301,  zsl: 0.5758, gzsl: seen=0.8498, unseen=0.0773, h=0.1417\n",
      "ep: 6,  lr: 0.000010, loss: 0.8169,  zsl: 0.5794, gzsl: seen=0.8536, unseen=0.0802, h=0.1467\n",
      "ep: 7,  lr: 0.000010, loss: 0.8116,  zsl: 0.5896, gzsl: seen=0.8528, unseen=0.0818, h=0.1494\n",
      "ep: 8,  lr: 0.000010, loss: 0.8039,  zsl: 0.5938, gzsl: seen=0.8529, unseen=0.0944, h=0.1699\n",
      "ep: 9,  lr: 0.000010, loss: 0.7971,  zsl: 0.5939, gzsl: seen=0.8560, unseen=0.0937, h=0.1690\n",
      "best_ep: 8, zsl: 0.5938, gzsl: seen=0.8529, unseen=0.0944, h=0.1699\n",
      "zsl: 0.5938, gzsl: seen=0.8529, unseen=0.0944, h=0.1699\n"
     ]
    }
   ],
   "source": [
    "AwA1_data = os.path.join(zsl_data_dir,'AwA1_data')\n",
    "model_dir = 'models'\n",
    "log_dir = 'logs'\n",
    "if not os.path.isdir(model_dir): os.mkdir(model_dir)\n",
    "if not os.path.isdir(log_dir): os.mkdir(log_dir)\n",
    "\n",
    "# run the example training script\n",
    "! python cvcZSL/train.py --dataset $AwA1_data --ways 16 --shots 4 --lr 1e-5 \\\n",
    "--opt_decay 1e-4 --step_size 500 --num_epochs 10 \\\n",
    "--log_file $log_dir/eps_lr5_opt4_ss500_w16_s4 \\\n",
    "--model_file $model_dir/lr5_opt4_ss500_w16_s4.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/zsl-example/data/AwA1_data\n",
      "Namespace(dataset='../../data/zsl-example/data/AwA1_data', gamma=0.5, hidden_dim=1600, log_file='temp.log', log_to_file=True, lr=1e-05, model_file='models/lr5_opt4_ss500_w16_s4.pt', nthreads=8, num_epochs=1000, opt_decay=0.001, shots=4, step_size=200, ways=32, weight_model='weightnet')\n",
      "Traceback (most recent call last):\n",
      "  File \"cvcZSL/test.py\", line 160, in <module>\n",
      "    model = torch.load(model_file_name)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 581, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../../data/zsl-example/data/AwA1_data/models/lr5_opt4_ss500_w16_s4.pt'\n"
     ]
    }
   ],
   "source": [
    "print(AwA1_data)\n",
    "! python cvcZSL/test.py --dataset $AwA1_data --model_file models/lr5_opt4_ss500_w16_s4.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Testing\n",
    "## This is just to test the limited dataset creation\n",
    "Let's now create a limited dataset for ZSL that we can use for training. Recall that for ZSL we are interested in splitting off a couple of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be located in '../../data'\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/SubLoader/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f73df2ad90e4c989b54f8cb75a00ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/SubLoader/raw/train-images-idx3-ubyte.gz to ../../data/SubLoader/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/SubLoader/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab29a628ab747a0880e97f7718c9129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/SubLoader/raw/train-labels-idx1-ubyte.gz to ../../data/SubLoader/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/SubLoader/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5cc52e69e34f179374bfef5b2d87e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/SubLoader/raw/t10k-images-idx3-ubyte.gz to ../../data/SubLoader/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/SubLoader/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06bce7afe564b8facaefa8ab374a9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/SubLoader/raw/t10k-labels-idx1-ubyte.gz to ../../data/SubLoader/raw\n",
      "Processing...\n",
      "Done!\n",
      "Dataset sizes: {'train': 1000, 'val': 165, 'pred': 2}\n",
      "Class names: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# use helper to create the dataloaders\n",
    "tmp = mnist_limited_dataloader(data_transforms,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               pred_size=0.01,\n",
    "                               sample_size=1000)\n",
    "dataloaders, dataset_sizes, class_names = tmp \n",
    "print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# preview the dataset\n",
    "dataset_preview(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline model 'resnet18'...\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 4.564 Acc: 0.312\n",
      "val Loss: 31.7464 Acc: 0.1515\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 2.0088 Acc: 0.53\n",
      "val Loss: 2.0453 Acc: 0.5576\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 3.5946 Acc: 0.459\n",
      "val Loss: 1.7764 Acc: 0.4182\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 1.304 Acc: 0.602\n",
      "val Loss: 0.8335 Acc: 0.6606\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.9008 Acc: 0.72\n",
      "val Loss: 0.609 Acc: 0.8061\n",
      "Training complete in 0.0m 4.3705456256866455s\n",
      "Best val Acc: 0.8061\n",
      "> Saved results to 'resnet18_results_2020-12-14T082336.csv'.\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model_name = 'resnet18'\n",
    "\n",
    "output_dir='output'\n",
    "num_epochs = 5\n",
    "# prepare the pre-trained model: \n",
    "#   Note the following considerations given our dataset for ResNet\n",
    "#     -> MNIST data are 1-channel (grascale) of size and has 10 output classes\n",
    "#     -> ResNet model expects 3-channel (RGB) images of size 224x224 as input \n",
    "#        and has 1000 output classes\n",
    "#     == We must changet the last fully connected layer to match 10 classes\n",
    "# keep features unchanged\n",
    "num_features = model.fc.in_features\n",
    "# change the output layer to match number of new classes\n",
    "num_classes = 10\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "# change the first conv layer for single channel images\n",
    "model.conv1 = torch.nn.Conv1d(1, 64, (7, 7), (2, 2), (3, 3), bias=False)\n",
    "# ref: https://discuss.pytorch.org/t/altering-resnet18-for-single-channel-images/29198/10\n",
    "\n",
    "# move model to the GPU\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# use helper function to train the model (outputs model and Pandas DF)\n",
    "print(f'\\nTraining baseline model \\'{model_name}\\'...')\n",
    "model, results_df,_ = train_model(device, model, dataloaders, \n",
    "                                       dataset_sizes, output_dir=output_dir, \n",
    "                                       num_epochs=num_epochs)\n",
    "\n",
    "# save the data for others to use\n",
    " # <-- train_model should have created this dir\n",
    "results_file = f'{model_name}_results_{time.strftime(\"%Y-%m-%dT%H%M%S\")}.csv'\n",
    "results_df.to_csv(os.path.join(output_dir,results_file),\n",
    "                  columns=results_df.columns)\n",
    "print(f'> Saved results to \\'{results_file}\\'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1728 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model using the prediction set held-off\n",
    "model.eval()\n",
    "dataloader_iter = iter(dataloaders['pred'])\n",
    "inputs, labels = next(dataloader_iter)\n",
    "inputs = inputs.cuda()\n",
    "# make predictions an plot the results\n",
    "fig = plot_classes_preds(model,inputs,labels,class_names) \n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
