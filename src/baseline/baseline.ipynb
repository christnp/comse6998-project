{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:      3.7.8\n",
      "PyTorch Version:     1.7.1+cu101\n",
      "Torchvision Version: 0.8.2+cu101\n",
      "CUDA Version:        10.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# this is necessary to use the common functions\n",
    "# assumes directory structure was maintained\n",
    "sys.path.insert(0, '../common/')\n",
    "# from common.torch_utils import train_model,get_device\n",
    "# from torch_utils import (train_model, \n",
    "#                          mnist_dataloader, \n",
    "#                          dataset_preview)\n",
    "from torch_utils import *\n",
    "\n",
    "# print some versions\n",
    "print(f'Python Version:      {platform.python_version()}')\n",
    "print(f'PyTorch Version:     {torch.__version__}')\n",
    "print(f'Torchvision Version: {torchvision.__version__}')\n",
    "print(f'CUDA Version:        {torch.version.cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********************************\n",
      "GPU Available:  True\n",
      "Current Device: cuda:0 (Tesla T4)\n",
      "***********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # use a GPU if there is one available\n",
    "cuda_availability = torch.cuda.is_available()\n",
    "if cuda_availability:\n",
    "    device = torch.device('cuda:{}'.format(torch.cuda.current_device()))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device_name = torch.cuda.get_device_name()\n",
    "print('\\n***********************************')\n",
    "print(f'GPU Available:  {cuda_availability}')\n",
    "print(f'Current Device: {device} ({device_name})')\n",
    "print('***********************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_dataloader(data_transform, batch_size, \n",
    "#                      data_dir='../../data', download=True,\n",
    "#                      train=True):\n",
    "#     if not os.path.isdir(data_dir):\n",
    "#         os.mkdir(data_dir)\n",
    "\n",
    "#     # get the data\n",
    "#     dataset = torchvision.datasets.MNIST(root=data_dir, \n",
    "#                                         train=train,\n",
    "#                                         download=download, \n",
    "#                                         transform=data_transform)\n",
    "#     print(f'Data is located in \\'{data_dir}\\'')\n",
    "\n",
    "#     # make the dataloader\n",
    "#     dataloader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "#                                              batch_size=batch_size,\n",
    "#                                              shuffle=True, \n",
    "#                                              num_workers=4)\n",
    "#     return {'dataset':dataset, 'dataloader':dataloader}\n",
    "\n",
    "\n",
    "# def train_model(device, model, dataloaders, criterion=None, \n",
    "#                 optimizer=None, scheduler=None, num_epochs=100, \n",
    "#                 checkpoints=10, output_dir='output', \n",
    "#                 status=1, train_acc=0, track_steps=False,\n",
    "#                 seed=414921):\n",
    "#     ''' Helper function to train PyTorch model based on parameters '''\n",
    "#     # create the model directory if it doesn't exist\n",
    "#     if not os.path.isdir(output_dir):\n",
    "#         os.mkdir(output_dir)\n",
    "\n",
    "#     # configure the training if it was not specified by user\n",
    "#     if not criterion:\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "#     if not optimizer:\n",
    "#         optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "#     if not scheduler:\n",
    "#         exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "#     # send the model to the device\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     since = time.time()\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#     best_acc = 0.0\n",
    "#     metrics = []\n",
    "#     step_metrics = [] # if track_steps=True\n",
    "#     training_step = 0\n",
    "#     acc_reached = False\n",
    "#     for epoch in range(num_epochs):\n",
    "#         epoch_start_time = time.time()\n",
    "#         if (epoch) % status == 0 or epoch == num_epochs-1:\n",
    "#             print()\n",
    "#             print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#             print('-' * 10)\n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train()\n",
    "#             else:\n",
    "#                 model.eval()\n",
    "#             epoch_phase_start_time = time.time()\n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0\n",
    "#             for inputs, labels in dataloaders[phase]:\n",
    "#                 step_start_time = time.time()\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 # forward\n",
    "#                 # track history if only in train\n",
    "#                 with torch.set_grad_enabled(phase == 'train'):\n",
    "#                     outputs = model(inputs)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                     # backward + optimize only if in training phase\n",
    "#                     if phase == 'train':\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "#                         if track_steps:\n",
    "#                             # store per step metrics (WARNING! lots of data)\n",
    "#                             step_metrics.append({\n",
    "#                                 'device': device,\n",
    "#                                 'epoch': epoch,\n",
    "#                                 'training_step': training_step,\n",
    "#                                 'training_step_loss': loss.item(),\n",
    "#                                 'training_step_time': time.time() - step_start_time\n",
    "#                             })\n",
    "#                         training_step += 1\n",
    "#                 # statistics\n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step()\n",
    "#             epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "#             epoch_phase_end_time = time.time()\n",
    "            \n",
    "#             # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc.item()\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "#             # check if training accuracy has met target, if so signal exit\n",
    "#             if (train_acc > 0) and (epoch_acc.item() >= train_acc) and phase == 'train':\n",
    "#                 acc_reached = True\n",
    "#                 print()\n",
    "#                 print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#                 print('-' * 10)\n",
    "                \n",
    "#             if (epoch) % status == 0 or epoch == num_epochs-1 or acc_reached:\n",
    "#                 print(f'{phase} Loss: {round(epoch_loss, 4)} Acc: {round(epoch_acc.item(), 4)}')\n",
    "#             else:\n",
    "#                 prog = '-' * int(((epoch) % status))\n",
    "#                 print('\\r{}|{}'.format(prog,epoch),end='')\n",
    "                \n",
    "#             # store per epoch metrics\n",
    "#             metrics.append({\n",
    "#                             'device': device,\n",
    "#                             'epoch': epoch,\n",
    "#                             'training_epoch_loss': loss.item(),\n",
    "#                             'training_epoch_acc': epoch_acc.item(),\n",
    "#                             'training_epoch_time': time.time() - epoch_start_time\n",
    "#                         })\n",
    "\n",
    "#         ####### save checkpoint after epoch\n",
    "#         if (epoch > 0 and epoch != num_epochs-1) and \\\n",
    "#             ((epoch+1) % checkpoints == 0 and os.path.isdir(output_dir)):\n",
    "#             checkpoint=os.path.join(output_dir,\n",
    "#                                 f'epoch{epoch+1}_checkpoint_model.th')\n",
    "#             torch.save({\n",
    "#                 'epoch': epoch + 1,\n",
    "#                 'state_dict': model.state_dict(),\n",
    "#                 'best_acc': best_acc,\n",
    "#             }, checkpoint)\n",
    "#             # dump the data for later\n",
    "#             json_file = os.path.join(output_dir,\n",
    "#                                     f'epoch{epoch+1}_checkpoint_metrics.json')\n",
    "#             with open(json_file, 'w') as fp:\n",
    "#                 json.dump(metrics, fp)\n",
    "#         #######\n",
    "        \n",
    "#         # if the target accuracy was reached during this epoch, it is time to exit\n",
    "#         if acc_reached: \n",
    "#             break\n",
    "    \n",
    "#     ####### save final checkpoint\n",
    "#     if os.path.isdir(output_dir):\n",
    "#         checkpoint= os.path.join(output_dir, 'final_model.th')\n",
    "#         # save the model\n",
    "#         torch.save({\n",
    "#             'state_dict': model.state_dict(),\n",
    "#             'best_acc': best_acc,\n",
    "#         }, checkpoint)\n",
    "#         # dump the data for later\n",
    "#         metric_path = os.path.join(output_dir,'final_metrics.json')\n",
    "#         with open(metric_path, 'w') as fp:\n",
    "#             json.dump(metrics, fp)\n",
    "#     #######\n",
    "    \n",
    "#     time_elapsed = time.time() - since\n",
    "#     print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "#     print(f'Best val Acc: {round(best_acc, 4)}')\n",
    "#     # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     # set up return structures\n",
    "#     metrics_df = pd.DataFrame(data=metrics)\n",
    "#     step_metrics_df = pd.DataFrame(data=step_metrics) if step_metrics else None\n",
    "        \n",
    "#     return model, metrics_df, step_metrics_df\n",
    "\n",
    "\n",
    "#     def get_device(verbose=False):\n",
    "#         # use a GPU if there is one available\n",
    "#         cuda_availability = torch.cuda.is_available()\n",
    "#         if cuda_availability:\n",
    "#             device = torch.device('cuda:{}'.format(torch.cuda.current_device()))\n",
    "#         else:\n",
    "#             device = 'cpu'\n",
    "#         device_name = torch.cuda.get_device_name()\n",
    "#         print('\\n***********************************')\n",
    "#         print(f'GPU Available:  {cuda_availability}')\n",
    "#         print(f'Current Device: {device} ({device_name})')\n",
    "#         print('***********************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be located in '../../data'\n",
      "Dataset sizes: {'train': 60000, 'val': 9900, 'pred': 100}\n",
      "Class names: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transform.Resize(224,224), # MNIST are 28x28, ResNet used 224x224\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #         transform.Resize(224,224), # MNIST are 28x28, ResNet used 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "}\n",
    "# datasets = {}\n",
    "# dataloaders = {}\n",
    "# dataset_sizes = {}\n",
    "# for phase in data_transforms:\n",
    "#     if phase == 'val':\n",
    "#         tmp = mnist_dataloader(data_transforms[phase],batch_size=BATCH_SIZE)\n",
    "#     elif phase == 'predict':\n",
    "#         tmp = mnist_dataloader(data_transforms[phase],batch_size=4)\n",
    "#     else:         \n",
    "#         tmp = mnist_dataloader(data_transforms[phase],batch_size=BATCH_SIZE,train=False)\n",
    "#     datasets[phase] = tmp['dataset']\n",
    "#     dataloaders[phase] = tmp['dataloader']\n",
    "#     dataset_sizes[phase] = tmp['dataset_size']\n",
    "    \n",
    "tmp = mnist_dataloader(data_transforms,batch_size=BATCH_SIZE,pred_size=0.01)\n",
    "dataloaders, dataset_sizes, class_names = tmp \n",
    "print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# preview the dataset\n",
    "dataset_preview(dataloaders['val'])\n",
    "\n",
    "\n",
    "# train_set = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,\n",
    "#                                         download=False, transform=data_transforms['train'])\n",
    "# val_set = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False,\n",
    "#                                        download=False, transform=data_transforms['val'])\n",
    "# image_datasets = {'train': train_set, 'val': val_set}\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCHSIZE,\n",
    "#                                               shuffle=True, num_workers=4)\n",
    "#                for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# class_names = image_datasets['train'].classes\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "# print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch PyTorch model for reset50\n",
    "# Use Resnet18, as our dataset is small and only has two classes\n",
    "# model = models.resnet18(pretrained=True)\n",
    "model = models.resnet50(pretrained=True)\n",
    "# Note the considerations we must make:\n",
    "#   -> MNIST data are 1-channel (grascale) of size and has 10 output classes\n",
    "#   -> ResNet model expects 3-channel (RGB) images of size 224x224 as input and has 1000 output classes\n",
    "#   == We must changet the last fully connected layer to match 10 classes, and transform the input to be 224\n",
    "num_classes = 10\n",
    "# prepare the pre-trained model\n",
    "num_features = model.fc.in_features\n",
    "# change the output layer to match number of new classes\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "# change the first conv layer for single channel images\n",
    "model.conv1 = torch.nn.Conv1d(1, 64, (7, 7), (2, 2), (3, 3), bias=False)\n",
    "# ref: https://discuss.pytorch.org/t/altering-resnet18-for-single-channel-images/29198/10\n",
    "\n",
    "# move model to the GPU\n",
    "cudnn.benchmark = True\n",
    "\n",
    "model, results_df,_ = train_model(device, model, dataloaders, dataset_sizes, num_epochs=3)\n",
    "\n",
    "# save the data for others to use\n",
    "# results_file = 'resnet18_{}.csv'.format(hardware)\n",
    "# df_path = os.path.join(save_dir,results_file)\n",
    "# results_df.to_csv(df_path,columns=results_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 6, 4, 9, 1, 2, 4, 4, 2, 9, 8, 1, 3, 9, 4, 3, 8, 8, 4, 4, 0, 5, 7,\n",
      "        5, 1, 4, 6, 1, 1, 9, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x3456 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "inputs, labels = next(iter(dataloaders['pred']))\n",
    "inputs = inputs.cuda()\n",
    "# make predictions an plot the results\n",
    "plot_classes_preds(model,inputs,labels,class_names) \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
