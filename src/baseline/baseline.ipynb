{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:      3.7.8\n",
      "PyTorch Version:     1.7.1+cu101\n",
      "Torchvision Version: 0.8.2+cu101\n",
      "CUDA Version:        10.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# this is necessary to use the common functions\n",
    "# assumes directory structure was maintained\n",
    "sys.path.insert(0, '../common/')\n",
    "# from common.torch_utils import train_model,get_device\n",
    "from torch_utils import (train_model, \n",
    "                         mnist_dataloader, \n",
    "                         dataset_preview)\n",
    "\n",
    "# print some versions\n",
    "print(f'Python Version:      {platform.python_version()}')\n",
    "print(f'PyTorch Version:     {torch.__version__}')\n",
    "print(f'Torchvision Version: {torchvision.__version__}')\n",
    "print(f'CUDA Version:        {torch.version.cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********************************\n",
      "GPU Available:  True\n",
      "Current Device: cuda:0 (Tesla T4)\n",
      "***********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # use a GPU if there is one available\n",
    "cuda_availability = torch.cuda.is_available()\n",
    "if cuda_availability:\n",
    "    device = torch.device('cuda:{}'.format(torch.cuda.current_device()))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device_name = torch.cuda.get_device_name()\n",
    "print('\\n***********************************')\n",
    "print(f'GPU Available:  {cuda_availability}')\n",
    "print(f'Current Device: {device} ({device_name})')\n",
    "print('***********************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mnist_dataloader(data_transform, batch_size, \n",
    "#                      data_dir='../../data', download=True,\n",
    "#                      train=True):\n",
    "#     if not os.path.isdir(data_dir):\n",
    "#         os.mkdir(data_dir)\n",
    "\n",
    "#     # get the data\n",
    "#     dataset = torchvision.datasets.MNIST(root=data_dir, \n",
    "#                                         train=train,\n",
    "#                                         download=download, \n",
    "#                                         transform=data_transform)\n",
    "#     print(f'Data is located in \\'{data_dir}\\'')\n",
    "\n",
    "#     # make the dataloader\n",
    "#     dataloader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "#                                              batch_size=batch_size,\n",
    "#                                              shuffle=True, \n",
    "#                                              num_workers=4)\n",
    "#     return {'dataset':dataset, 'dataloader':dataloader}\n",
    "\n",
    "\n",
    "# def train_model(device, model, dataloaders, criterion=None, \n",
    "#                 optimizer=None, scheduler=None, num_epochs=100, \n",
    "#                 checkpoints=10, output_dir='output', \n",
    "#                 status=1, train_acc=0, track_steps=False,\n",
    "#                 seed=414921):\n",
    "#     ''' Helper function to train PyTorch model based on parameters '''\n",
    "#     # create the model directory if it doesn't exist\n",
    "#     if not os.path.isdir(output_dir):\n",
    "#         os.mkdir(output_dir)\n",
    "\n",
    "#     # configure the training if it was not specified by user\n",
    "#     if not criterion:\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "#     if not optimizer:\n",
    "#         optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "#     if not scheduler:\n",
    "#         exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "#     # send the model to the device\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     since = time.time()\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#     best_acc = 0.0\n",
    "#     metrics = []\n",
    "#     step_metrics = [] # if track_steps=True\n",
    "#     training_step = 0\n",
    "#     acc_reached = False\n",
    "#     for epoch in range(num_epochs):\n",
    "#         epoch_start_time = time.time()\n",
    "#         if (epoch) % status == 0 or epoch == num_epochs-1:\n",
    "#             print()\n",
    "#             print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#             print('-' * 10)\n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train()\n",
    "#             else:\n",
    "#                 model.eval()\n",
    "#             epoch_phase_start_time = time.time()\n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0\n",
    "#             for inputs, labels in dataloaders[phase]:\n",
    "#                 step_start_time = time.time()\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 # forward\n",
    "#                 # track history if only in train\n",
    "#                 with torch.set_grad_enabled(phase == 'train'):\n",
    "#                     outputs = model(inputs)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                     # backward + optimize only if in training phase\n",
    "#                     if phase == 'train':\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "#                         if track_steps:\n",
    "#                             # store per step metrics (WARNING! lots of data)\n",
    "#                             step_metrics.append({\n",
    "#                                 'device': device,\n",
    "#                                 'epoch': epoch,\n",
    "#                                 'training_step': training_step,\n",
    "#                                 'training_step_loss': loss.item(),\n",
    "#                                 'training_step_time': time.time() - step_start_time\n",
    "#                             })\n",
    "#                         training_step += 1\n",
    "#                 # statistics\n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step()\n",
    "#             epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "#             epoch_phase_end_time = time.time()\n",
    "            \n",
    "#             # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc.item()\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "#             # check if training accuracy has met target, if so signal exit\n",
    "#             if (train_acc > 0) and (epoch_acc.item() >= train_acc) and phase == 'train':\n",
    "#                 acc_reached = True\n",
    "#                 print()\n",
    "#                 print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#                 print('-' * 10)\n",
    "                \n",
    "#             if (epoch) % status == 0 or epoch == num_epochs-1 or acc_reached:\n",
    "#                 print(f'{phase} Loss: {round(epoch_loss, 4)} Acc: {round(epoch_acc.item(), 4)}')\n",
    "#             else:\n",
    "#                 prog = '-' * int(((epoch) % status))\n",
    "#                 print('\\r{}|{}'.format(prog,epoch),end='')\n",
    "                \n",
    "#             # store per epoch metrics\n",
    "#             metrics.append({\n",
    "#                             'device': device,\n",
    "#                             'epoch': epoch,\n",
    "#                             'training_epoch_loss': loss.item(),\n",
    "#                             'training_epoch_acc': epoch_acc.item(),\n",
    "#                             'training_epoch_time': time.time() - epoch_start_time\n",
    "#                         })\n",
    "\n",
    "#         ####### save checkpoint after epoch\n",
    "#         if (epoch > 0 and epoch != num_epochs-1) and \\\n",
    "#             ((epoch+1) % checkpoints == 0 and os.path.isdir(output_dir)):\n",
    "#             checkpoint=os.path.join(output_dir,\n",
    "#                                 f'epoch{epoch+1}_checkpoint_model.th')\n",
    "#             torch.save({\n",
    "#                 'epoch': epoch + 1,\n",
    "#                 'state_dict': model.state_dict(),\n",
    "#                 'best_acc': best_acc,\n",
    "#             }, checkpoint)\n",
    "#             # dump the data for later\n",
    "#             json_file = os.path.join(output_dir,\n",
    "#                                     f'epoch{epoch+1}_checkpoint_metrics.json')\n",
    "#             with open(json_file, 'w') as fp:\n",
    "#                 json.dump(metrics, fp)\n",
    "#         #######\n",
    "        \n",
    "#         # if the target accuracy was reached during this epoch, it is time to exit\n",
    "#         if acc_reached: \n",
    "#             break\n",
    "    \n",
    "#     ####### save final checkpoint\n",
    "#     if os.path.isdir(output_dir):\n",
    "#         checkpoint= os.path.join(output_dir, 'final_model.th')\n",
    "#         # save the model\n",
    "#         torch.save({\n",
    "#             'state_dict': model.state_dict(),\n",
    "#             'best_acc': best_acc,\n",
    "#         }, checkpoint)\n",
    "#         # dump the data for later\n",
    "#         metric_path = os.path.join(output_dir,'final_metrics.json')\n",
    "#         with open(metric_path, 'w') as fp:\n",
    "#             json.dump(metrics, fp)\n",
    "#     #######\n",
    "    \n",
    "#     time_elapsed = time.time() - since\n",
    "#     print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "#     print(f'Best val Acc: {round(best_acc, 4)}')\n",
    "#     # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     # set up return structures\n",
    "#     metrics_df = pd.DataFrame(data=metrics)\n",
    "#     step_metrics_df = pd.DataFrame(data=step_metrics) if step_metrics else None\n",
    "        \n",
    "#     return model, metrics_df, step_metrics_df\n",
    "\n",
    "\n",
    "#     def get_device(verbose=False):\n",
    "#         # use a GPU if there is one available\n",
    "#         cuda_availability = torch.cuda.is_available()\n",
    "#         if cuda_availability:\n",
    "#             device = torch.device('cuda:{}'.format(torch.cuda.current_device()))\n",
    "#         else:\n",
    "#             device = 'cpu'\n",
    "#         device_name = torch.cuda.get_device_name()\n",
    "#         print('\\n***********************************')\n",
    "#         print(f'GPU Available:  {cuda_availability}')\n",
    "#         print(f'Current Device: {device} ({device_name})')\n",
    "#         print('***********************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is located in '../../data'\n",
      "Data is located in '../../data'\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "}\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "for phase in data_transforms:\n",
    "    if phase == 'val':\n",
    "        tmp = mnist_dataloader(data_transforms[phase],BATCH_SIZE)\n",
    "    else:         \n",
    "        tmp = mnist_dataloader(data_transforms[phase],BATCH_SIZE,train=False)\n",
    "    datasets[phase] = tmp['dataset']\n",
    "    dataloaders[phase] = tmp['dataloader']\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_set = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,\n",
    "#                                         download=False, transform=data_transforms['train'])\n",
    "# val_set = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False,\n",
    "#                                        download=False, transform=data_transforms['val'])\n",
    "# image_datasets = {'train': train_set, 'val': val_set}\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCHSIZE,\n",
    "#                                               shuffle=True, num_workers=4)\n",
    "#                for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# class_names = image_datasets['train'].classes\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "# print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_preview(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['val']))\n",
    "# select 4 unique classes to demo\n",
    "uni, ind = np.unique(classes, return_index=True)\n",
    "use = np.random.choice(ind, 4, replace=False)\n",
    "# display samles\n",
    "# title = f'Samples of \\'{}\\' Dataset'\n",
    "title = f'Samples of Dataset'\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "fig.suptitle(title, fontsize=16)\n",
    "for i,u in enumerate(use):\n",
    "    axn = fig.add_subplot(1, 4, i+1)\n",
    "#     axn.set_title(real_names[class_names[classes[u]]])\n",
    "#     axn.set_title(real_names[class_names[classes[u]]])\n",
    "    axn.axis('off')\n",
    "    axn.imshow(inputs[u].permute(1, 2, 0))     \n",
    "plt.tight_layout(pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch PyTorch model for reset50\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# use Resnet18, as our dataset is small and only has two classes\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Note the considerations we must make:\n",
    "#   -> MNIST data are 1-channel (grascale) of size and has 10 output classes\n",
    "#   -> ResNet model expects 3-channel (RGB) images of size 224x224 as input and has 1000 output classes\n",
    "#   == We must changet the last fully connected layer to match 10 classes, and transform the input to be 224\n",
    "num_classes = 10\n",
    "input_size = 224 # <-- MNIST is 32x32, so we must change it.\n",
    "# prepare the pre-trained model\n",
    "num_features = model.fc.in_features\n",
    "# change the output layer to match number of new classes\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# if feature extraction only (not finetuning)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# move model to the GPU\n",
    "cudnn.benchmark = True\n",
    "\n",
    "model, results_df,_ = train_model(device, model, dataloaders, num_epochs=1)\n",
    "\n",
    "# save the data for others to use\n",
    "# results_file = 'resnet18_{}.csv'.format(hardware)\n",
    "# df_path = os.path.join(save_dir,results_file)\n",
    "# results_df.to_csv(df_path,columns=results_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
