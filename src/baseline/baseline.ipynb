{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Training and Prediction Results\n",
    "This notebook will provide us with a baseline for comparing the four methods of training on datasets with limited data (data augmentation, transfer learning, one-shot learning, and zero-shot learning). For the baseline model, we train using the full dataset; wherease, for the other four methods we will train only on a small-subset of the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:      3.7.8\n",
      "PyTorch Version:     1.7.1+cu101\n",
      "Torchvision Version: 0.8.2+cu101\n",
      "CUDA Version:        10.1\n",
      "\n",
      "***********************************\n",
      "GPU Available:  True\n",
      "Current Device: cuda:0 (Tesla T4)\n",
      "***********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# this is necessary to use the common functions\n",
    "# assumes directory structure was maintained\n",
    "sys.path.insert(0, '../common/')\n",
    "# from common.torch_utils import train_model,get_device\n",
    "# from torch_utils import (train_model, \n",
    "#                          mnist_dataloader, \n",
    "#                          dataset_preview)\n",
    "from torch_utils import *\n",
    "\n",
    "# print some versions\n",
    "print(f'Python Version:      {platform.python_version()}')\n",
    "print(f'PyTorch Version:     {torch.__version__}')\n",
    "print(f'Torchvision Version: {torchvision.__version__}')\n",
    "print(f'CUDA Version:        {torch.version.cuda}')\n",
    "\n",
    "# get device (defaults to GPU if available)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We need to collect the MNIST data and create the dataloaders for PyTorch. To make a clean notebook, we have created a helper function to do most of the work (refer to `/src/common/torch_utils.py`). For training the base model, we will use a batch size of 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be located in '../../data'\n",
      "Dataset sizes: {'train': 60000, 'val': 9900, 'pred': 100}\n",
      "Class names: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# use helper to create the dataloaders\n",
    "tmp = mnist_dataloader(data_transforms,batch_size=BATCH_SIZE,pred_size=0.01)\n",
    "dataloaders, dataset_sizes, class_names = tmp \n",
    "print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# preview the dataset\n",
    "dataset_preview(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model on the Full Dataset\n",
    "For the base model we will use a ResNet, specifically the ResNet-18. The MNIST dataset is relatively small (60k training images and 10k validation images) and has only 10 output classifiers, making a larger ResNet (e.g., ResNet-50) unnecessary. Before we can use the pretrained model, however, a couple of considerations are made. First, ResNet was pretrained with the ImageNet dataset which consists of 224x224 RGB (3-channel) images; however, the MNIST dataset consists of 28x28 Grayscale (1-channel) images. The first two dimensions (HxW) are not an issue for the ResNet-18 model (we may have to retrain vs. finetune), but the third dimension discrepency will cause an error for the PyTorch model. The solution to this issue, as stated in this [reference](https://discuss.pytorch.org/t/altering-resnet18-for-single-channel-images/29198/10), is to modify the first convolutional layer changing it from `torch.nn.Conv1d(3, 64, ...)` to `torch.nn.Conv1d(1, 64, ...)` as shown in the code below.  \n",
    "\n",
    "Second, ImageNet conists of 1000 classifications for it's labeled dataset. The MNIST dataset, as mentioned earlier, has only 10 classifications (representing handwritten numbers 0 through 10). Again, PyTorch will give a dimension mismatch error if we try to use the MNIST dataset without modifying the network. To resolve the output mismatch, we modify the output fully-connected layer with this simple line of code: `model.fc = nn.Linear(model.fc.in_features, 10)`.   \n",
    "\n",
    "With these two modifications to the ResNet-18 netowrk, we can initiate the training process. To once again keep this notebook clean and to encourage consistent code reuse, we have put the details of the trainning process in a helper function, `train_model()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline model 'ResNet18'...\n",
      "\n",
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 2.8331 Acc: 0.16\n",
      "val Loss: 7.9599 Acc: 0.1111\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 3.9737 Acc: 0.34\n",
      "val Loss: 433.0386 Acc: 0.1111\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 4.6408 Acc: 0.3\n",
      "val Loss: 6867.251 Acc: 0.1111\n",
      "Training complete in 0.0m 1.5853326320648193s\n",
      "Best val Acc: 0.1111\n",
      "> Saved results to 'ResNet18_results_2020-12-14T090051.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Use Torchvision Resnet18 for base model since our \n",
    "# dataset is small and only has 10 classes this should\n",
    "# be well suited. DO NOT PRETRAIN FOR BASE MODEL.\n",
    "pretrained = False\n",
    "base_models = [{'name' : 'ResNet18', 'model': models.resnet18(pretrained=pretrained) }]\n",
    "# model = models.resnet18(pretrained=False)\n",
    "\n",
    "# \n",
    "output_dir='output'\n",
    "num_epochs = 3\n",
    "for M in base_models:\n",
    "    model_name = M['name']\n",
    "    model = M['model']\n",
    "    # prepare the pre-trained model: \n",
    "    #   Note the following considerations given our dataset for ResNet\n",
    "    #     -> MNIST data are 1-channel (grascale) of size and has 10 output classes\n",
    "    #     -> ResNet model expects 3-channel (RGB) images of size 224x224 as input \n",
    "    #        and has 1000 output classes\n",
    "    #     == We must changet the last fully connected layer to match 10 classes\n",
    "    # keep features unchanged\n",
    "    num_features = model.fc.in_features\n",
    "    # change the output layer to match number of new classes\n",
    "    num_classes = 10\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    # change the first conv layer for single channel images\n",
    "    model.conv1 = torch.nn.Conv1d(1, 64, (7, 7), (2, 2), (3, 3), bias=False)\n",
    "    # ref: https://discuss.pytorch.org/t/altering-resnet18-for-single-channel-images/29198/10\n",
    "\n",
    "    # move model to the GPU\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # use helper function to train the model (outputs model and Pandas DF)\n",
    "    print(f'\\nTraining baseline model \\'{model_name}\\'...')\n",
    "    model, results_df,_ = train_model(device, model, dataloaders, \n",
    "                                           dataset_sizes, output_dir=output_dir, \n",
    "                                           num_epochs=num_epochs)\n",
    "\n",
    "    # save the data for others to use\n",
    "     # <-- train_model should have created this dir\n",
    "    results_file = f'{model_name}_results_{time.strftime(\"%Y-%m-%dT%H%M%S\")}.csv'\n",
    "    results_df.to_csv(os.path.join(output_dir,results_file),\n",
    "                      columns=results_df.columns)\n",
    "    print(f'> Saved results to \\'{results_file}\\'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model from Full Dataset Training\n",
    "During our data pre-processing (in the `mnist_dataloader()` function) we have intentionally split off 10% of the validation dataset that we can use for evaluating the model. First, notice that in 3 epochs we were able to achieve 97% accuracy using the ResNet-18 pretrained model (not bad!). Now, let's go ahead and use the `plot_classes_preds()` function from a somewhat unrealated PyTorch [tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) (referenece linked). The results of this function are below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the prediction set held-off\n",
    "model.eval()\n",
    "dataloader_iter = iter(dataloaders['pred'])\n",
    "inputs, labels = next(dataloader_iter)\n",
    "inputs = inputs.cuda()\n",
    "# make predictions an plot the results\n",
    "fig = plot_classes_preds(model,inputs,labels,class_names) \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Limited Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model on the Limited Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model from Limited Dataset Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In closing, this notebook was intended to provide us with a baseline, a \"zero\" if you will. I think it is pretty clear from the work in this notebook that the ResNet-18 is a reasonable target model to finetune as a classifier for the MNIST dataset. Now, let's see how other methods can compare when dealing with a limited dataset for training.\n",
    "\n",
    "## References:\n",
    "[1] https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
