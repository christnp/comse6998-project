{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Shot Learning Training and Prediction Results\n",
    "\n",
    "reference:\n",
    "https://towardsdatascience.com/building-a-one-shot-learning-network-with-pytorch-d1c3a5fafa4a\n",
    "https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18\n",
    "\n",
    "[3] \"We are interested in the problem of learning and recognition of <u>categories</u> (as opposed to individual objects)\" \n",
    "[3] \"Another aspect that we wish to emphasize is the ability to learn with minimal supervision.\"\n",
    "\n",
    "[3] Li Fei-Fei, R. Fergus and P. Perona, \"One-shot learning of object categories,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 4, pp. 594-611, April 2006, doi: 10.1109/TPAMI.2006.79."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:      3.7.8\n",
      "PyTorch Version:     1.7.1+cu101\n",
      "Torchvision Version: 0.8.2+cu101\n",
      "CUDA Version:        10.1\n",
      "\n",
      "***********************************\n",
      "GPU Available:  True\n",
      "Current Device: cuda:0 (Tesla T4)\n",
      "***********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# this is necessary to use the common functions\n",
    "# assumes directory structure was maintained\n",
    "sys.path.insert(0, '../common/')\n",
    "# from common.torch_utils import train_model,get_device\n",
    "# from torch_utils import (train_model, \n",
    "#                          mnist_dataloader, \n",
    "#                          dataset_preview)\n",
    "from torch_utils import *\n",
    "\n",
    "# print some versions\n",
    "print(f'Python Version:      {platform.python_version()}')\n",
    "print(f'PyTorch Version:     {torch.__version__}')\n",
    "print(f'Torchvision Version: {torchvision.__version__}')\n",
    "print(f'CUDA Version:        {torch.version.cuda}')\n",
    "\n",
    "# get device (defaults to GPU if available)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep as consistent as possible with the reference article, let's observe the following excerpt:\n",
    "\n",
    "> Batch Size: Since we are learning how similar are two images, the batch size needs to be pretty big in order for the model to be generalisable especially for a dataset like this with many different categories. Therefore we used a batch size of 128.   \n",
    ">\n",
    "> Learning Rate: We tested with several learning rates from 0.001 to 0.0005, and selected a 0.0006 which provided the best loss decreasing rate.   \n",
    ">\n",
    "> Optimizer and Loss: We adopted the traditional Adam optimizer for this network with the binary cross entropy (BCE) loss with logits.\n",
    "\n",
    "Another excerpt from the article that will drive design decisions:\n",
    ">... could be due to the fact that the kernel size of the convolutional layers is fairly small (3x3), which gives a small receptive field. For a problem of computing similarity between two images, it may perhaps be beneficial to look at a “bigger picture” of the two images instead of focusing on small details, and hence a larger receptive field proposed in the original network worked better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
